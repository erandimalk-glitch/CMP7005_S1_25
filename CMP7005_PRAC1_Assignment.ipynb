{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erandimalk-glitch/CMP7005_S1_25/blob/main/CMP7005_PRAC1_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CMP7005 – Programming for Data Analysis\n",
        "## PRAC1 – From Data to Application Development\n",
        "#\n",
        "#\n",
        "## Main analysis notebook:\n",
        "### - Task 1: Data handling (Import, Merge)\n",
        "### - Task 2: EDA (Fundamental Understanding, Preprocessing, Statistics + Visualisation)\n",
        "### - Task 3: Model building (regression + classification)\n",
        "#\n",
        "#\n",
        "#### NOTE: This assignement assumes that all India air quality CSV files are stored in a folder called \"data/\" and each file is of the form \"<City>_data.csv\" with consistent columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "O91neTiSmV8M"
      },
      "id": "O91neTiSmV8M"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n"
      ],
      "metadata": {
        "id": "NFgmu3BEmPhF"
      },
      "id": "NFgmu3BEmPhF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = Path(\"data\")\n",
        "\n",
        "\n",
        "def load_city_csvs(data_dir: Path = DATA_DIR):\n",
        "    \\\"\\\"\\\"Return a sorted list of all *_data.csv files in the given directory.\\\"\\\"\\\"\n",
        "    return sorted(data_dir.glob(\"*_data.csv\"))\n",
        "\n",
        "\n",
        "def parse_city_name(path: Path) -> str:\n",
        "    \\\"\\\"\\\"Extract the city name from a filename like 'Delhi_data.csv' -> 'Delhi'.\\\"\\\"\\\"\n",
        "    return path.stem.replace(\"_data\", \"\")"
      ],
      "metadata": {
        "id": "Z7CCITsBngjV"
      },
      "id": "Z7CCITsBngjV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = load_city_csvs()\n",
        "print(\"Found CSV files:\")\n",
        "for f in csv_files:\n",
        "    print(\"  -\", f.name)\n",
        "\n",
        "frames = []\n",
        "for path in csv_files:\n",
        "    city_name = parse_city_name(path)\n",
        "    df_city = pd.read_csv(path)\n",
        "    df_city[\"City\"] = city_name\n",
        "    frames.append(df_city)\n",
        "\n",
        "df = pd.concat(frames, ignore_index=True)\n",
        "\n",
        "print(\"\\\\nMerged DataFrame shape:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LJ55SJFIn20e"
      },
      "id": "LJ55SJFIn20e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of rows:\", df.shape[0])\n",
        "print(\"Number of columns:\", df.shape[1])\n",
        "print(\"\\\\nColumn names:\\\\n\", df.columns.tolist())\n",
        "\n",
        "print(\"\\\\nData types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\\\nSample of data:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\\\nMissing values per column:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "print(\"\\\\nBasic descriptive statistics (numeric columns):\")\n",
        "display(df.describe(include=\"number\"))\n",
        "\n",
        "print(\"\\\\nUnique cities:\", df[\"City\"].nunique())\n",
        "print(\"Cities:\", sorted(df[\"City\"].unique()))\n",
        "\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
        "df = df.sort_values([\"City\", \"Date\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"\\\\nCheck Date conversion:\")\n",
        "display(df[[\"City\", \"Date\"]].head())"
      ],
      "metadata": {
        "id": "BZYKUNBooDG1"
      },
      "id": "BZYKUNBooDG1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollutant_cols = [\n",
        "    \"PM2.5\",\n",
        "    \"PM10\",\n",
        "    \"NO\",\n",
        "    \"NO2\",\n",
        "    \"NOx\",\n",
        "    \"NH3\",\n",
        "    \"CO\",\n",
        "    \"SO2\",\n",
        "    \"O3\",\n",
        "    \"Benzene\",\n",
        "    \"Toluene\",\n",
        "    \"Xylene\",\n",
        "]\n",
        "\n",
        "num_duplicates = df.duplicated().sum()\n",
        "print(f\"Number of exact duplicate rows: {num_duplicates}\")\n",
        "df = df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "df = df.dropna(subset=[\"Date\", \"City\"]).reset_index(drop=True)\n",
        "\n",
        "mask_all_pollutants_nan = df[pollutant_cols].isna().all(axis=1)\n",
        "mask_aqi_nan = df[\"AQI\"].isna()\n",
        "rows_dropped = df[mask_all_pollutants_nan & mask_aqi_nan].shape[0]\n",
        "print(\"Rows dropped because all pollutants and AQI are NaN:\", rows_dropped)\n",
        "df = df[~(mask_all_pollutants_nan & mask_aqi_nan)].reset_index(drop=True)\n",
        "\n",
        "for col in pollutant_cols:\n",
        "    df[col] = df.groupby(\"City\")[col].transform(\n",
        "        lambda s: s.fillna(s.median())\n",
        "    )\n",
        "\n",
        "df[\"AQI\"] = df.groupby(\"City\")[\"AQI\"].transform(\n",
        "    lambda s: s.fillna(s.median())\n",
        ")\n",
        "\n",
        "\n",
        "def aqi_to_bucket(aqi: float) -> str:\n",
        "    if pd.isna(aqi):\n",
        "        return \"Unknown\"\n",
        "    if aqi <= 50:\n",
        "        return \"Good\"\n",
        "    elif aqi <= 100:\n",
        "        return \"Satisfactory\"\n",
        "    elif aqi <= 200:\n",
        "        return \"Moderate\"\n",
        "    elif aqi <= 300:\n",
        "        return \"Poor\"\n",
        "    elif aqi <= 400:\n",
        "        return \"Very Poor\"\n",
        "    else:\n",
        "        return \"Severe\"\n",
        "\n",
        "\n",
        "df[\"AQI_Bucket\"] = df[\"AQI_Bucket\"].fillna(df[\"AQI\"].apply(aqi_to_bucket))\n",
        "\n",
        "print(\"\\\\nMissing data after preprocessing:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "df[\"Year\"] = df[\"Date\"].dt.year\n",
        "df[\"Month\"] = df[\"Date\"].dt.month\n",
        "df[\"Day\"] = df[\"Date\"].dt.day\n",
        "\n",
        "\n",
        "def month_to_season(m: int) -> str:\n",
        "    if m in (12, 1, 2):\n",
        "        return \"Winter\"\n",
        "    elif m in (3, 4, 5):\n",
        "        return \"Spring\"\n",
        "    elif m in (6, 7, 8):\n",
        "        return \"Summer\"\n",
        "    else:\n",
        "        return \"Autumn\"\n",
        "\n",
        "\n",
        "df[\"Season\"] = df[\"Month\"].apply(month_to_season)\n",
        "\n",
        "df[\"PM_ratio\"] = df[\"PM2.5\"] / df[\"PM10\"]\n",
        "df[\"PM_ratio\"] = df[\"PM_ratio\"].replace([np.inf, -np.inf], np.nan)\n",
        "df[\"PM_ratio\"] = df[\"PM_ratio\"].fillna(df[\"PM_ratio\"].median())\n",
        "\n",
        "df_clean = df.copy()\n",
        "display(df_clean.head())\n"
      ],
      "metadata": {
        "id": "GNrsvlrnoSPg"
      },
      "id": "GNrsvlrnoSPg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "sns.histplot(df_clean[\"AQI\"], kde=True, bins=40)\n",
        "plt.title(\"Distribution of AQI\")\n",
        "plt.xlabel(\"AQI\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "top_cities = df_clean[\"City\"].value_counts().head(6).index.tolist()\n",
        "plt.figure()\n",
        "sns.boxplot(\n",
        "    data=df_clean[df_clean[\"City\"].isin(top_cities)],\n",
        "    x=\"City\",\n",
        "    y=\"PM2.5\",\n",
        ")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"PM2.5 distribution for top 6 cities\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "sns.countplot(data=df_clean, x=\"AQI_Bucket\", order=df_clean[\"AQI_Bucket\"].value_counts().index)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Counts by AQI bucket\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "sample = df_clean.sample(min(5000, len(df_clean)), random_state=42)\n",
        "sns.scatterplot(\n",
        "    data=sample,\n",
        "    x=\"PM2.5\",\n",
        "    y=\"AQI\",\n",
        "    hue=\"City\",\n",
        "    alpha=0.4,\n",
        "    legend=False,\n",
        ")\n",
        "plt.title(\"AQI vs PM2.5 (sample)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "avg_aqi_city = df_clean.groupby(\"City\")[\"AQI\"].mean().sort_values(ascending=False)\n",
        "plt.figure()\n",
        "sns.barplot(x=avg_aqi_city.values, y=avg_aqi_city.index)\n",
        "plt.xlabel(\"Average AQI\")\n",
        "plt.ylabel(\"City\")\n",
        "plt.title(\"Average AQI by city\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "avg_aqi_season = df_clean.groupby([\"City\", \"Season\"])[\"AQI\"].mean().reset_index()\n",
        "plt.figure()\n",
        "sns.lineplot(\n",
        "    data=avg_aqi_season[avg_aqi_season[\"City\"].isin(top_cities)],\n",
        "    x=\"Season\",\n",
        "    y=\"AQI\",\n",
        "    hue=\"City\",\n",
        "    marker=\"o\",\n",
        ")\n",
        "plt.title(\"Seasonal average AQI for top cities\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "corr_cols = pollutant_cols + [\"AQI\", \"PM_ratio\"]\n",
        "corr = df_clean[corr_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "plt.title(\"Correlation matrix – pollutants and AQI\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\\\nCorrelation of AQI with key pollutants:\")\n",
        "print(corr[\"AQI\"].sort_values(ascending=False))\n"
      ],
      "metadata": {
        "id": "P_JdCGNDohtS"
      },
      "id": "P_JdCGNDohtS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = pollutant_cols + [\"PM_ratio\"]\n",
        "\n",
        "cutoff_year = 2019\n",
        "train_df = df_clean[df_clean[\"Year\"] < cutoff_year]\n",
        "test_df = df_clean[df_clean[\"Year\"] >= cutoff_year]\n",
        "\n",
        "print(\"Training rows:\", train_df.shape[0])\n",
        "print(\"Test rows:\", test_df.shape[0])\n",
        "\n",
        "X_train = train_df[feature_cols].values\n",
        "y_train_reg = train_df[\"AQI\"].values\n",
        "y_train_clf = train_df[\"AQI_Bucket\"].values\n",
        "\n",
        "X_test = test_df[feature_cols].values\n",
        "y_test_reg = test_df[\"AQI\"].values\n",
        "y_test_clf = test_df[\"AQI_Bucket\"].values\n",
        "\n",
        "\n",
        "def evaluate_regression_model(name: str, y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"\\\\n[{name}] Regression performance\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"MAE  : {mae:.3f}\")\n",
        "    print(f\"RMSE : {rmse:.3f}\")\n",
        "    print(f\"R^2  : {r2:.3f}\")"
      ],
      "metadata": {
        "id": "Ep2yjNHxowzh"
      },
      "id": "Ep2yjNHxowzh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"scaler\", StandardScaler())]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[(\"num\", numeric_transformer, list(range(len(feature_cols))))],\n",
        "    remainder=\"drop\",\n",
        ")\n",
        "\n",
        "linreg_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "linreg_model.fit(X_train, y_train_reg)\n",
        "y_pred_linreg = linreg_model.predict(X_test)\n",
        "evaluate_regression_model(\"Linear Regression\", y_test_reg, y_pred_linreg)"
      ],
      "metadata": {
        "id": "1EigdUdSo4og"
      },
      "id": "1EigdUdSo4og",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_reg_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", KNeighborsRegressor(n_neighbors=5)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "knn_reg_model.fit(X_train, y_train_reg)\n",
        "y_pred_knn_reg = knn_reg_model.predict(X_test)\n",
        "evaluate_regression_model(\"KNN Regression (k=5)\", y_test_reg, y_pred_knn_reg)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(y_test_reg, y_pred_knn_reg, alpha=0.3)\n",
        "plt.xlabel(\"Actual AQI\")\n",
        "plt.ylabel(\"Predicted AQI (KNN)\")\n",
        "plt.title(\"Actual vs Predicted AQI – KNN Regression\")\n",
        "plt.plot([y_test_reg.min(), y_test_reg.max()],\n",
        "         [y_test_reg.min(), y_test_reg.max()],\n",
        "         color=\"red\", linestyle=\"--\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L-sS_wizo-5x"
      },
      "id": "L-sS_wizo-5x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_clf_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", KNeighborsClassifier(n_neighbors=7)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "knn_clf_model.fit(X_train, y_train_clf)\n",
        "y_pred_knn_clf = knn_clf_model.predict(X_test)\n",
        "\n",
        "print(\"\\\\n[KNN Classification] AQI_Bucket performance\")\n",
        "print(\"-\" * 40)\n",
        "print(classification_report(y_test_clf, y_pred_knn_clf))\n",
        "\n",
        "cm = confusion_matrix(y_test_clf, y_pred_knn_clf)\n",
        "plt.figure()\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=np.unique(y_test_clf),\n",
        "    yticklabels=np.unique(y_test_clf),\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion matrix – KNN classifier for AQI_Bucket\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yeUkVyqOpH5_"
      },
      "id": "yeUkVyqOpH5_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", RandomForestClassifier(\n",
        "            n_estimators=150,\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "        )),\n",
        "    ]\n",
        ")\n",
        "\n",
        "rf_clf_model.fit(X_train, y_train_clf)\n",
        "y_pred_rf = rf_clf_model.predict(X_test)\n",
        "\n",
        "print(\"\\\\n[RandomForest Classification] AQI_Bucket performance\")\n",
        "print(\"-\" * 40)\n",
        "print(classification_report(y_test_clf, y_pred_rf))\n",
        "\n",
        "cm_rf = confusion_matrix(y_test_clf, y_pred_rf)\n",
        "plt.figure()\n",
        "sns.heatmap(\n",
        "    cm_rf,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Greens\",\n",
        "    xticklabels=np.unique(y_test_clf),\n",
        "    yticklabels=np.unique(y_test_clf),\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion matrix – RandomForest classifier for AQI_Bucket\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uPnOIybspOpl"
      },
      "id": "uPnOIybspOpl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "ARTIFACT_DIR = Path(\"artifacts\")\n",
        "ARTIFACT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "joblib.dump(df_clean, ARTIFACT_DIR / \"df_clean.pkl\")\n",
        "joblib.dump(feature_cols, ARTIFACT_DIR / \"feature_cols.pkl\")\n",
        "joblib.dump(knn_reg_model, ARTIFACT_DIR / \"knn_reg_model.pkl\")\n",
        "joblib.dump(rf_clf_model, ARTIFACT_DIR / \"rf_clf_model.pkl\")\n",
        "\n",
        "print(\"\\\\nSaved artefacts to:\", ARTIFACT_DIR.resolve())"
      ],
      "metadata": {
        "id": "NLPKS5VapWpP"
      },
      "id": "NLPKS5VapWpP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}